{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package inaugural to\n",
      "[nltk_data]     C:\\Users\\Kristine\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package inaugural is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import inaugural\n",
    "from collections import Counter\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "nltk.download('inaugural')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Learning Capstone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction\n",
    "\n",
    "The dataset is a collection of the inaugurals of all the presidents of the United States. My two aims of this project is to 1) using NLP, compare and contrast the most frequent words that the following presidents used: Roosevelt, Truman, Eisenhower, Kennedy, Johnson, Nixon, Carter, Reagan, Bush Sr, Clinton, Bush Jr and Obama. Then, we will use bag of words(BoW) and BoW features to create classification models such as linear regression, gradient boost, random forrest. which will determine if a word belongs to a presidents who is a democrat or to a president that is a republican. \n",
    "\n",
    "2) using TfidfVectorizer, analyse both Obama and Roosevelt's inaugurals. Furthermore, using SVD data reducer, we will optimise the process even further and will be able to group the sentences in the text into several different components and see how similar are they to each other. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised NLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1789-Washington.txt',\n",
       " '1793-Washington.txt',\n",
       " '1797-Adams.txt',\n",
       " '1801-Jefferson.txt',\n",
       " '1805-Jefferson.txt',\n",
       " '1809-Madison.txt',\n",
       " '1813-Madison.txt',\n",
       " '1817-Monroe.txt',\n",
       " '1821-Monroe.txt',\n",
       " '1825-Adams.txt',\n",
       " '1829-Jackson.txt',\n",
       " '1833-Jackson.txt',\n",
       " '1837-VanBuren.txt',\n",
       " '1841-Harrison.txt',\n",
       " '1845-Polk.txt',\n",
       " '1849-Taylor.txt',\n",
       " '1853-Pierce.txt',\n",
       " '1857-Buchanan.txt',\n",
       " '1861-Lincoln.txt',\n",
       " '1865-Lincoln.txt',\n",
       " '1869-Grant.txt',\n",
       " '1873-Grant.txt',\n",
       " '1877-Hayes.txt',\n",
       " '1881-Garfield.txt',\n",
       " '1885-Cleveland.txt',\n",
       " '1889-Harrison.txt',\n",
       " '1893-Cleveland.txt',\n",
       " '1897-McKinley.txt',\n",
       " '1901-McKinley.txt',\n",
       " '1905-Roosevelt.txt',\n",
       " '1909-Taft.txt',\n",
       " '1913-Wilson.txt',\n",
       " '1917-Wilson.txt',\n",
       " '1921-Harding.txt',\n",
       " '1925-Coolidge.txt',\n",
       " '1929-Hoover.txt',\n",
       " '1933-Roosevelt.txt',\n",
       " '1937-Roosevelt.txt',\n",
       " '1941-Roosevelt.txt',\n",
       " '1945-Roosevelt.txt',\n",
       " '1949-Truman.txt',\n",
       " '1953-Eisenhower.txt',\n",
       " '1957-Eisenhower.txt',\n",
       " '1961-Kennedy.txt',\n",
       " '1965-Johnson.txt',\n",
       " '1969-Nixon.txt',\n",
       " '1973-Nixon.txt',\n",
       " '1977-Carter.txt',\n",
       " '1981-Reagan.txt',\n",
       " '1985-Reagan.txt',\n",
       " '1989-Bush.txt',\n",
       " '1993-Clinton.txt',\n",
       " '1997-Clinton.txt',\n",
       " '2001-Bush.txt',\n",
       " '2005-Bush.txt',\n",
       " '2009-Obama.txt',\n",
       " '2013-Obama.txt',\n",
       " '2017-Trump.txt']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inaugural.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "roosevelt45 = inaugural.raw('1945-Roosevelt.txt') \n",
    "truman = inaugural.raw('1949-Truman.txt')\n",
    "eisenhower57 = inaugural.raw('1957-Eisenhower.txt')\n",
    "kennedy = inaugural.raw('1961-Kennedy.txt')\n",
    "johnson = inaugural.raw('1965-Johnson.txt')\n",
    "nixon73 = inaugural.raw('1973-Nixon.txt')\n",
    "carter = inaugural.raw('1977-Carter.txt')\n",
    "reagan85 = inaugural.raw('1985-Reagan.txt')\n",
    "bush_sr = inaugural.raw('1989-Bush.txt')\n",
    "clinton97 = inaugural.raw('1997-Clinton.txt')\n",
    "bush_jr05 = inaugural.raw('2005-Bush.txt')\n",
    "obama09 = inaugural.raw('2009-Obama.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Visual inspection identifies a form of punctuation spaCy does not\n",
    "    # recognize: the double dash '--'.  Better get rid of it now!\n",
    "    text = re.sub('--',' ',text)\n",
    "    text = re.sub('/\\\\n/g', \"\", text)\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
    "    text = re.sub('\\n\\n', \"\", text)\n",
    "    text = re.sub('\\'s ', '', text)\n",
    "    text = ' '.join(text.lower().split())\n",
    "    \n",
    "    return text\n",
    "#remove any unwanted characters - if not a - z or space!!!!!!!!!!!!!!!!!!! google regex\n",
    "#for president in address:\n",
    "    #president = clean_text(president)\n",
    "bush_sr =  ' '.join(bush_sr.split())\n",
    "roosevelt = clean_text(roosevelt45)\n",
    "truman = clean_text(truman)\n",
    "eisenhower = clean_text(eisenhower57)\n",
    "kennedy = clean_text(kennedy)\n",
    "johnson = clean_text(johnson)\n",
    "nixon = clean_text(nixon73)\n",
    "carter = clean_text(carter)\n",
    "reagan = clean_text(reagan85)\n",
    "bush = clean_text(bush_sr)\n",
    "clinton = clean_text(clinton97)\n",
    "bush_jr = clean_text(bush_jr05)\n",
    "obama = clean_text(obama09)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "addresses = roosevelt + truman + eisenhower + kennedy + johnson + nixon + carter + reagan + bush + clinton + bush_jr + obama\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "roosevelt_doc = nlp(roosevelt) \n",
    "truman_doc = nlp(truman)\n",
    "eisenhower_doc = nlp(eisenhower)\n",
    "kennedy_doc = nlp(kennedy)\n",
    "johnson_doc = nlp(johnson)\n",
    "nixon_doc = nlp(nixon)\n",
    "carter_doc = nlp(carter)\n",
    "reagan_doc = nlp(reagan)\n",
    "bush_sr_doc = nlp(bush_sr)\n",
    "clinton_doc = nlp(clinton)\n",
    "bush_jr_doc = nlp(bush_jr)\n",
    "obama_doc = nlp(obama)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roosvelt: [('shall', 7), ('peace', 5), ('learned', 5), ('today', 4), ('men', 4), ('test', 3), ('way', 3), ('simple', 2), ('courage', 2), ('presence', 2)]\n",
      "Truman: [('nations', 21), ('world', 17), ('peace', 12), ('freedom', 11), ('free', 11), ('people', 10), ('united', 10), ('new', 8), ('peoples', 8), ('believe', 8)]\n",
      "Eisenhower: [('nations', 14), ('world', 13), ('seek', 10), ('freedom', 10), ('peace', 9), ('people', 9), ('help', 6), ('justice', 5), ('know', 5), ('earth', 5)]\n",
      "Kennedy: [('let', 11), ('sides', 8), ('new', 7), ('pledge', 7), ('world', 6), ('citizens', 5), ('power', 5), ('shall', 5), ('ask', 5), ('president', 4)]\n",
      "Johnson: [('change', 11), ('nation', 10), ('people', 9), ('union', 9), ('man', 8), ('world', 7), ('old', 7), ('american', 6), ('land', 6), ('liberty', 6)]\n",
      "Nixon: [('new', 15), ('peace', 14), ('let', 13), ('america', 12), ('world', 10), ('responsibility', 10), ('great', 9), ('government', 9), ('shall', 7), ('home', 7)]\n",
      "Carter: [('nation', 10), ('new', 9), ('strength', 6), ('spirit', 6), ('people', 6), ('human', 5), ('world', 5), ('government', 4), ('freedom', 4), ('dream', 4)]\n",
      "Reagan: [('people', 15), ('government', 15), ('world', 14), ('freedom', 12), ('time', 9), ('new', 9), ('human', 9), ('years', 7), ('history', 7), ('american', 7)]\n",
      "Busn Sr: [('new', 14), ('world', 9), ('free', 9), ('friends', 8), ('things', 8), ('hand', 8), ('great', 8), ('America', 7), ('today', 7), ('day', 7)]\n",
      "Clinton: [('new', 29), ('century', 20), ('nation', 13), ('time', 12), ('land', 11), ('america', 11), ('people', 11), ('promise', 10), ('world', 10), ('government', 10)]\n",
      "Bush JR: [('freedom', 25), ('liberty', 14), ('america', 12), ('¦', 12), ('s', 11), ('nation', 9), ('country', 8), ('world', 8), ('america¡', 8), ('americans', 8)]\n",
      "Obama: [('nation', 12), ('new', 11), ('america', 6), ('people', 6), ('work', 6), ('common', 6), ('world', 6), ('let', 6), ('today', 5), ('generation', 5)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Utility function to calculate how frequently words appear in the text.\n",
    "def word_frequencies(text, include_stop=False):\n",
    "    \n",
    "    # Build a list of words.\n",
    "    # Strip out punctuation and, optionally, stop words.\n",
    "    words = []\n",
    "    for token in text:\n",
    "        if not token.is_punct and (not token.is_stop or include_stop):\n",
    "            words.append(token.text)\n",
    "            \n",
    "    # Build and return a Counter object containing word counts.\n",
    "    return Counter(words) \n",
    "# The most frequent words:\n",
    " \n",
    "roosevelt_doc_freq = word_frequencies(roosevelt_doc).most_common(10)\n",
    "truman_doc_freq  = word_frequencies(truman_doc).most_common(10)\n",
    "eisenhower_doc_freq  = word_frequencies(eisenhower_doc).most_common(10)\n",
    "kennedy_doc_freq  = word_frequencies(kennedy_doc).most_common(10)\n",
    "johnson_doc_freq  = word_frequencies(johnson_doc).most_common(10)\n",
    "nixon_doc_freq  = word_frequencies(nixon_doc).most_common(10)\n",
    "carter_doc_freq  = word_frequencies(carter_doc).most_common(10)\n",
    "reagan_doc_freq  = word_frequencies(reagan_doc).most_common(10)\n",
    "bush_sr_doc_freq  = word_frequencies(bush_sr_doc).most_common(10)\n",
    "clinton_doc_freq  = word_frequencies(clinton_doc).most_common(10)\n",
    "bush_jr_doc_freq  = word_frequencies(bush_jr_doc).most_common(10)\n",
    "obama_doc_freq  = word_frequencies(obama_doc).most_common(10)\n",
    "print('Roosvelt:',roosevelt_doc_freq) \n",
    "print('Truman:',truman_doc_freq) \n",
    "print('Eisenhower:',eisenhower_doc_freq) \n",
    "print('Kennedy:',kennedy_doc_freq) \n",
    "print('Johnson:',johnson_doc_freq) \n",
    "print('Nixon:',nixon_doc_freq) \n",
    "print('Carter:',carter_doc_freq) \n",
    "print('Reagan:',reagan_doc_freq) \n",
    "print('Busn Sr:',bush_sr_doc_freq) \n",
    "print('Clinton:',clinton_doc_freq) \n",
    "print('Bush JR:',bush_jr_doc_freq) \n",
    "print('Obama:',obama_doc_freq) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roosvelt: [('shall', 7), ('peace', 6), ('learn', 5), ('today', 4), ('man', 4), ('way', 4), ('test', 3), ('friend', 2), ('simple', 2), ('courage', 2)]\n",
      "Truman: [('world', 23), ('people', 20), ('nation', 18), ('peace', 15), ('freedom', 13), ('free', 11), ('country', 11), ('man', 10), ('United', 10), ('security', 9)]\n",
      "Eisenhower: [('nation', 17), ('people', 15), ('world', 15), ('seek', 12), ('freedom', 11), ('peace', 10), ('know', 9), ('hope', 8), ('help', 8), ('great', 7)]\n",
      "Kennedy: [('let', 16), ('world', 8), ('side', 8), ('power', 7), ('new', 7), ('pledge', 7), ('nation', 6), ('ask', 6), ('citizen', 5), ('man', 5)]\n",
      "Johnson: [('man', 12), ('nation', 9), ('people', 9), ('change', 9), ('world', 7), ('old', 7), ('land', 6), ('union', 6), ('generation', 5), ('new', 5)]\n",
      "Nixon: [('let', 22), ('America', 21), ('peace', 19), ('world', 17), ('responsibility', 16), ('new', 15), ('nation', 14), ('great', 10), ('year', 9), ('home', 9)]\n",
      "Carter: [('new', 9), ('Nation', 7), ('strength', 7), ('nation', 7), ('spirit', 6), ('people', 6), ('world', 6), ('time', 5), ('good', 5), ('dream', 5)]\n",
      "Reagan: [('people', 16), ('world', 16), ('freedom', 14), ('time', 13), ('government', 11), ('new', 9), ('history', 9), ('Government', 9), ('human', 9), ('God', 8)]\n",
      "Busn Sr: [('new', 14), ('great', 12), ('thing', 10), ('work', 10), ('friend', 9), ('hand', 9), ('day', 9), ('good', 9), ('nation', 9), ('world', 9)]\n",
      "Clinton: [('new', 29), ('century', 20), ('America', 15), ('nation', 15), ('world', 15), ('time', 13), ('promise', 11), ('land', 11), ('people', 11), ('great', 10)]\n",
      "Bush JR: [('freedom', 24), ('America', 12), ('¦', 12), ('s', 11), ('nation', 11), ('liberty', 10), ('country', 8), ('time', 8), ('come', 8), ('world', 8)]\n",
      "Obama: [('nation', 15), ('new', 11), ('America', 9), ('generation', 8), ('work', 8), ('man', 7), ('world', 7), ('today', 6), ('meet', 6), ('time', 6)]\n"
     ]
    }
   ],
   "source": [
    "# Utility function to calculate how frequently lemas appear in the text.\n",
    "def lemma_frequencies(text, include_stop=False):\n",
    "    \n",
    "    # Build a list of lemas.\n",
    "    # Strip out punctuation and, optionally, stop words.\n",
    "    lemmas = []\n",
    "    for token in text:\n",
    "        if not token.is_punct and (not token.is_stop or include_stop):\n",
    "            lemmas.append(token.lemma_)\n",
    "            \n",
    "    # Build and return a Counter object containing word counts.\n",
    "    return Counter(lemmas)\n",
    "\n",
    "# Instantiate our list of most common lemmas.\n",
    "roosevelt_lemma_freq = lemma_frequencies(roosevelt_doc).most_common(10)\n",
    "truman_lemma_freq  = lemma_frequencies(truman_doc).most_common(10)\n",
    "eisenhower_lemma_freq  = lemma_frequencies(eisenhower_doc).most_common(10)\n",
    "kennedy_lemma_freq  = lemma_frequencies(kennedy_doc).most_common(10)\n",
    "johnson_lemma_freq  = lemma_frequencies(johnson_doc).most_common(10)\n",
    "nixon_lemma_freq  = lemma_frequencies(nixon_doc).most_common(10)\n",
    "carter_lemma_freq  = lemma_frequencies(carter_doc).most_common(10)\n",
    "reagan_lemma_freq  = lemma_frequencies(reagan_doc).most_common(10)\n",
    "bush_sr_lemma_freq  = lemma_frequencies(bush_sr_doc).most_common(10)\n",
    "clinton_lemma_freq  = lemma_frequencies(clinton_doc).most_common(10)\n",
    "bush_jr_lemma_freq  = lemma_frequencies(bush_jr_doc).most_common(10)\n",
    "obama_lemma_freq  = lemma_frequencies(obama_doc).most_common(10)\n",
    "print('Roosvelt:',roosevelt_lemma_freq) \n",
    "print('Truman:',truman_lemma_freq) \n",
    "print('Eisenhower:',eisenhower_lemma_freq) \n",
    "print('Kennedy:',kennedy_lemma_freq) \n",
    "print('Johnson:',johnson_lemma_freq) \n",
    "print('Nixon:',nixon_lemma_freq) \n",
    "print('Carter:',carter_lemma_freq) \n",
    "print('Reagan:',reagan_lemma_freq) \n",
    "print('Busn Sr:',bush_sr_lemma_freq) \n",
    "print('Clinton:',clinton_lemma_freq) \n",
    "print('Bush JR:',bush_jr_lemma_freq) \n",
    "print('Obama:',obama_lemma_freq) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Chief, Justice, ,, Mr., Vice, President, ,, m...</td>\n",
       "      <td>Democrat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(We, Americans, of, today, ,, together, with, ...</td>\n",
       "      <td>Democrat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(It, is, a, test, of, our, courage, of, our, r...</td>\n",
       "      <td>Democrat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(If, we, meet, that, test, successfully, and, ...</td>\n",
       "      <td>Democrat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(As, I, stand, here, today, ,, having, taken, ...</td>\n",
       "      <td>Democrat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0         1\n",
       "0  (Chief, Justice, ,, Mr., Vice, President, ,, m...  Democrat\n",
       "1  (We, Americans, of, today, ,, together, with, ...  Democrat\n",
       "2  (It, is, a, test, of, our, courage, of, our, r...  Democrat\n",
       "3  (If, we, meet, that, test, successfully, and, ...  Democrat\n",
       "4  (As, I, stand, here, today, ,, having, taken, ...  Democrat"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group into sentences.\n",
    "\n",
    "roosevelt_sents = [[sent, \"Democrat\"] for sent in roosevelt_doc.sents]\n",
    "truman_sents = [[sent, \"Democrat\"] for sent in truman_doc.sents]\n",
    "eisenhower_sents = [[sent, \"Republican\"] for sent in eisenhower_doc.sents]\n",
    "kennedy_sents = [[sent, \"Democrat\"] for sent in kennedy_doc.sents]\n",
    "johnson_sents = [[sent, \"Democrat\"] for sent in johnson_doc.sents]\n",
    "nixon_sents = [[sent, \"Republican\"] for sent in nixon_doc.sents]\n",
    "carter_sents = [[sent, \"Democrat\"] for sent in carter_doc.sents]\n",
    "reagan_sents = [[sent, \"Republican\"] for sent in reagan_doc.sents]\n",
    "bush_sr_sents = [[sent, \"Republican\"] for sent in bush_sr_doc.sents]\n",
    "clinton_sents = [[sent, \"Democrat\"] for sent in clinton_doc.sents]\n",
    "bush_jr_sents = [[sent, \"Republican\"] for sent in bush_jr_doc.sents]\n",
    "obama_sents = [[sent, \"Democrat\"] for sent in obama_doc.sents]\n",
    "\n",
    "\n",
    "# Combine the sentences from the two novels into one data frame.\n",
    "sentences = pd.DataFrame(roosevelt_sents + \n",
    "        truman_sents +\n",
    "        eisenhower_sents +\n",
    "        kennedy_sents +\n",
    "        johnson_sents +\n",
    "        nixon_sents +\n",
    "        carter_sents +\n",
    "        reagan_sents +\n",
    "        bush_sr_sents +\n",
    "        clinton_sents +\n",
    "        bush_jr_sents +\n",
    "        obama_sents)\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(text):\n",
    "    allwords = [token.lemma_\n",
    "               for token in text\n",
    "               if not token.is_punct\n",
    "               and not token.is_stop]\n",
    "    return [item[0] for item in Counter(allwords).most_common(2000)]\n",
    "\n",
    "def bow_features(sentences, common_words):\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['text_sentence'] = sentences[0]\n",
    "    df['text_party'] = sentences[1]\n",
    "    df.loc[:,common_words] = 0\n",
    "    \n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        words = [token.lemma_ \n",
    "                for token in sentence\n",
    "                if (\n",
    "                    not token.is_punct\n",
    "                    and not token.is_stop\n",
    "                    and token.lemma_ in common_words\n",
    "                )]\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "        if i%100 == 0:\n",
    "            print('Processing row {}'.format(i))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "roosevelt_words = bag_of_words(roosevelt_doc)\n",
    "truman_words = bag_of_words(truman_doc)\n",
    "eisenhower_words = bag_of_words(eisenhower_doc)\n",
    "kennedy_words = bag_of_words(kennedy_doc)\n",
    "johnson_words = bag_of_words(johnson_doc)\n",
    "nixon_words = bag_of_words(nixon_doc)\n",
    "carter_words = bag_of_words(carter_doc)\n",
    "reagan_words = bag_of_words(reagan_doc)\n",
    "bush_sr_words = bag_of_words(bush_sr_doc)\n",
    "clinton_words = bag_of_words(clinton_doc)\n",
    "bush_jr_words = bag_of_words(bush_jr_doc)\n",
    "obama_words = bag_of_words(obama_doc)\n",
    "\n",
    "common_words = set(roosevelt_words +\n",
    "        truman_words + \n",
    "        eisenhower_words + \n",
    "        kennedy_words +\n",
    "        johnson_words +\n",
    "        nixon_words +\n",
    "        carter_words +\n",
    "        reagan_words +\n",
    "        bush_sr_words +\n",
    "        clinton_words +\n",
    "        bush_jr_words +\n",
    "        obama_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 100\n",
      "Processing row 200\n",
      "Processing row 300\n",
      "Processing row 400\n",
      "Processing row 500\n",
      "Processing row 600\n",
      "Processing row 700\n",
      "Processing row 800\n",
      "Processing row 900\n",
      "Processing row 1000\n",
      "Processing row 1100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unclimbed</th>\n",
       "      <th>weight</th>\n",
       "      <th>State</th>\n",
       "      <th>stately</th>\n",
       "      <th>pretend</th>\n",
       "      <th>vast</th>\n",
       "      <th>prophet</th>\n",
       "      <th>connection</th>\n",
       "      <th>occur</th>\n",
       "      <th>1984</th>\n",
       "      <th>...</th>\n",
       "      <th>wound</th>\n",
       "      <th>importance</th>\n",
       "      <th>imperialism</th>\n",
       "      <th>Soviets</th>\n",
       "      <th>command</th>\n",
       "      <th>turmoil</th>\n",
       "      <th>sincere</th>\n",
       "      <th>repression</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_party</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Chief, Justice, ,, Mr., Vice, President, ,, m...</td>\n",
       "      <td>Democrat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(We, Americans, of, today, ,, together, with, ...</td>\n",
       "      <td>Democrat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(It, is, a, test, of, our, courage, of, our, r...</td>\n",
       "      <td>Democrat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(If, we, meet, that, test, successfully, and, ...</td>\n",
       "      <td>Democrat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(As, I, stand, here, today, ,, having, taken, ...</td>\n",
       "      <td>Democrat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2497 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  unclimbed weight State stately pretend vast prophet connection occur 1984  \\\n",
       "0         0      0     0       0       0    0       0          0     0    0   \n",
       "1         0      0     0       0       0    0       0          0     0    0   \n",
       "2         0      0     0       0       0    0       0          0     0    0   \n",
       "3         0      0     0       0       0    0       0          0     0    0   \n",
       "4         0      0     0       0       0    0       0          0     0    0   \n",
       "\n",
       "   ... wound importance imperialism Soviets command turmoil sincere  \\\n",
       "0  ...     0          0           0       0       0       0       0   \n",
       "1  ...     0          0           0       0       0       0       0   \n",
       "2  ...     0          0           0       0       0       0       0   \n",
       "3  ...     0          1           0       0       0       0       0   \n",
       "4  ...     0          0           0       0       0       0       0   \n",
       "\n",
       "  repression                                      text_sentence text_party  \n",
       "0          0  (Chief, Justice, ,, Mr., Vice, President, ,, m...   Democrat  \n",
       "1          0  (We, Americans, of, today, ,, together, with, ...   Democrat  \n",
       "2          0  (It, is, a, test, of, our, courage, of, our, r...   Democrat  \n",
       "3          0  (If, we, meet, that, test, successfully, and, ...   Democrat  \n",
       "4          0  (As, I, stand, here, today, ,, having, taken, ...   Democrat  \n",
       "\n",
       "[5 rows x 2497 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts = bow_features(sentences, common_words)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.9845788849347569\n",
      "\n",
      "Test set score: 0.5531914893617021\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "Y = word_counts['text_party']\n",
    "X = np.array(word_counts.drop(['text_sentence','text_party'], 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    Y,\n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state=0)\n",
    "train = rfc.fit(X_train, y_train)\n",
    "\n",
    "print('Training set score:', rfc.score(X_train, y_train))\n",
    "print('\\nTest set score:', rfc.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(843, 2495) (843,)\n",
      "Training set score: 0.963226571767497\n",
      "\n",
      "Test set score: 0.5638297872340425\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(penalty='l2') # No need to specify l2 as it's the default. But we put it for demonstration.\n",
    "train = lr.fit(X_train, y_train)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print('Training set score:', lr.score(X_train, y_train))\n",
    "print('\\nTest set score:', lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.8374851720047449\n",
      "\n",
      "Test set score: 0.5070921985815603\n"
     ]
    }
   ],
   "source": [
    "clf = ensemble.GradientBoostingClassifier()\n",
    "train = clf.fit(X_train, y_train)\n",
    "\n",
    "print('Training set score:', clf.score(X_train, y_train))\n",
    "print('\\nTest set score:', clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Chief Justice , Mr . Vice President , my friends , you will understand and , I believe , agree with my wish that the form of this inauguration be simple and its words brief .', 'We Americans of today , together with our allies , are passing through a period of supreme test .', 'If we meet that test  successfully and honorably  we shall perform a service of historic importance which men and women and children will honor throughout all time .', \"As I stand here today , having taken the solemn oath of office in the presence of my fellow countrymen  in the presence of our God  I know that it is America ' s purpose that we shall not fail .\"]\n",
      "['My fellow citizens :', 'I stand here today humbled by the task before us , grateful for the trust you have bestowed , mindful of the sacrifices borne by our ancestors .', 'Forty - four Americans have now taken the presidential oath .', 'So it has been .']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import inaugural\n",
    "\n",
    "\n",
    "#reading in the data, this time in the form of paragraphs\n",
    "roosevelt = inaugural.paras('1945-Roosevelt.txt') \n",
    "truman = inaugural.paras('1949-Truman.txt')\n",
    "eisenhower = inaugural.paras('1957-Eisenhower.txt')\n",
    "kennedy = inaugural.paras('1961-Kennedy.txt')\n",
    "johnson = inaugural.paras('1965-Johnson.txt')\n",
    "nixon = inaugural.paras('1973-Nixon.txt')\n",
    "carter = inaugural.paras('1977-Carter.txt')\n",
    "reagan = inaugural.paras('1985-Reagan.txt')\n",
    "bush_sr = inaugural.paras('1989-Bush.txt')\n",
    "clinton = inaugural.paras('1997-Clinton.txt')\n",
    "bush_jr = inaugural.paras('2005-Bush.txt')\n",
    "obama = inaugural.paras('2009-Obama.txt')\n",
    "#processing\n",
    "roosevelt_paras=[]\n",
    "for paragraph in roosevelt:\n",
    "    para=paragraph[0]\n",
    "    #removing the double-dash from all words\n",
    "    para=[re.sub(r'--','',word) for word in para]\n",
    "    para=[re.sub('/\\\\n/g', \"\", word) for word in para]\n",
    "    #Forming each paragraph into a string and adding it to the list of strings.\n",
    "    roosevelt_paras.append(' '.join(para))\n",
    "\n",
    "print(roosevelt_paras[0:4])\n",
    "\n",
    "obama_paras=[]\n",
    "for paragraph in obama:\n",
    "    para=paragraph[0]\n",
    "    #removing the double-dash from all words\n",
    "    para=[re.sub(r'--','',word) for word in para]\n",
    "    para=[re.sub('/\\\\n/g', \"\", word) for word in para]\n",
    "    #Forming each paragraph into a string and adding it to the list of strings.\n",
    "    obama_paras.append(' '.join(para))\n",
    "\n",
    "print(obama_paras[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 14\n",
      "Original sentence: As I stand here today , having taken the solemn oath of office in the presence of my fellow countrymen  in the presence of our God  I know that it is America ' s purpose that we shall not fail .\n",
      "Tf_idf vector: {'god': 0.5573997703441839, 'fellow': 0.5573997703441839, 'shall': 0.41611405025804205, 'today': 0.4532770556937}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "X_train, X_test = train_test_split(roosevelt_paras, test_size=0.4, random_state=0)\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.5, # drop words that occur in more than half the paragraphs\n",
    "                             min_df=2, # only use words that appear at least twice\n",
    "                             stop_words='english', \n",
    "                             lowercase=True, #convert everything to lower case (since Alice in Wonderland has the HABIT of CAPITALIZING WORDS for EMPHASIS)\n",
    "                             use_idf=True,#we definitely want to use inverse document frequencies in our weighting\n",
    "                             norm=u'l2', #Applies a correction factor so that longer paragraphs and shorter paragraphs get treated equally\n",
    "                             smooth_idf=True #Adds 1 to all document frequencies, as if an extra document existed that used every word once.  Prevents divide-by-zero errors\n",
    "                            )\n",
    "\n",
    "\n",
    "#Applying the vectorizer\n",
    "roosevelt_paras_tfidf=vectorizer.fit_transform(roosevelt_paras)\n",
    "print(\"Number of features: %d\" % roosevelt_paras_tfidf.get_shape()[1])\n",
    "\n",
    "#splitting into training and test sets\n",
    "X_train_tfidf, X_test_tfidf= train_test_split(roosevelt_paras_tfidf, test_size=0.4, random_state=0)\n",
    "\n",
    "\n",
    "#Reshapes the vectorizer output into something people can read\n",
    "X_train_tfidf_csr = X_train_tfidf.tocsr()\n",
    "\n",
    "#number of paragraphs\n",
    "n = X_train_tfidf_csr.shape[0]\n",
    "#A list of dictionaries, one per paragraph\n",
    "tfidf_bypara = [{} for _ in range(0,n)]\n",
    "#List of features\n",
    "terms = vectorizer.get_feature_names()\n",
    "#for each paragraph, lists the feature words and their tf-idf scores\n",
    "for i, j in zip(*X_train_tfidf_csr.nonzero()):\n",
    "    tfidf_bypara[i][terms[j]] = X_train_tfidf_csr[i, j]\n",
    "\n",
    "#Keep in mind that the log base 2 of 1 is 0, so a tf-idf score of 0 indicates that the word was present once in that sentence.\n",
    "print('Original sentence:', X_train[5])\n",
    "print('Tf_idf vector:', tfidf_bypara[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 27\n",
      "Original sentence: On this day , we gather because we have chosen hope over fear , unity of purpose over conflict and discord .\n",
      "Tf_idf vector: {'hope': 0.7366305251840556, 'day': 0.6762954009654822}\n"
     ]
    }
   ],
   "source": [
    "X_train1, X_test1 = train_test_split(obama_paras, test_size=0.4, random_state=0)\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.5, # drop words that occur in more than half the paragraphs\n",
    "                             min_df=2, # only use words that appear at least twice\n",
    "                             stop_words='english', \n",
    "                             lowercase=True, #convert everything to lower case (since Alice in Wonderland has the HABIT of CAPITALIZING WORDS for EMPHASIS)\n",
    "                             use_idf=True,#we definitely want to use inverse document frequencies in our weighting\n",
    "                             norm=u'l2', #Applies a correction factor so that longer paragraphs and shorter paragraphs get treated equally\n",
    "                             smooth_idf=True #Adds 1 to all document frequencies, as if an extra document existed that used every word once.  Prevents divide-by-zero errors\n",
    "                            )\n",
    "\n",
    "\n",
    "#Applying the vectorizer\n",
    "obama_paras_tfidf=vectorizer.fit_transform(obama_paras)\n",
    "print(\"Number of features: %d\" % obama_paras_tfidf.get_shape()[1])\n",
    "\n",
    "#splitting into training and test sets\n",
    "X_train_tfidf1, X_test_tfidf1= train_test_split(obama_paras_tfidf, test_size=0.4, random_state=0)\n",
    "\n",
    "\n",
    "#Reshapes the vectorizer output into something people can read\n",
    "X_train_tfidf_csr1 = X_train_tfidf1.tocsr()\n",
    "\n",
    "#number of paragraphs\n",
    "n = X_train_tfidf_csr1.shape[0]\n",
    "#A list of dictionaries, one per paragraph\n",
    "tfidf_bypara1 = [{} for _ in range(0,n)]\n",
    "#List of features\n",
    "terms1 = vectorizer.get_feature_names()\n",
    "#for each paragraph, lists the feature words and their tf-idf scores\n",
    "for i, j in zip(*X_train_tfidf_csr1.nonzero()):\n",
    "    tfidf_bypara1[i][terms1[j]] = X_train_tfidf_csr1[i, j]\n",
    "\n",
    "#Keep in mind that the log base 2 of 1 is 0, so a tf-idf score of 0 indicates that the word was present once in that sentence.\n",
    "print('Original sentence:', X_train1[5])\n",
    "print('Tf_idf vector:', tfidf_bypara1[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Almighty God has blessed our land in many ways .',\n",
       " 'We have learned that we cannot live alone , at peace ; that our own well - being is dependent on the well - being of other nations far away .',\n",
       " 'I remember that my old schoolmaster , Dr . Peabody , said , in days that seemed to us then to be secure and untroubled : \" Things in life will not always run smoothly .',\n",
       " 'So we pray to Him now for the vision to see our way clearly  to see the way that leads to a better life for ourselves and for all our fellow men  to the achievement of His will to peace on earth .',\n",
       " 'We have learned to be citizens of the world , members of the human community .',\n",
       " \"As I stand here today , having taken the solemn oath of office in the presence of my fellow countrymen  in the presence of our God  I know that it is America ' s purpose that we shall not fail .\",\n",
       " 'Chief Justice , Mr . Vice President , my friends , you will understand and , I believe , agree with my wish that the form of this inauguration be simple and its words brief .',\n",
       " 'We can and we will achieve such a peace .',\n",
       " 'We have learned the simple truth , as Emerson said , that \" The only way to have a friend is to be one .\"']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['On this day , we come to proclaim an end to the petty grievances and false promises , the recriminations and worn - out dogmas that for far too long have strangled our politics .',\n",
       " 'For us , they fought and died , in places like Concord and Gettysburg ; Normandy and Khe Sahn .',\n",
       " 'These are the indicators of crisis , subject to data and statistics .',\n",
       " 'Now , there are some who question the scale of our ambitions  who suggest that our system cannot tolerate too many big plans .',\n",
       " 'Time and again these men and women struggled and sacrificed and worked till their hands were raw so that we might live a better life .',\n",
       " 'On this day , we gather because we have chosen hope over fear , unity of purpose over conflict and discord .',\n",
       " 'As we consider the road that unfolds before us , we remember with humble gratitude those brave Americans who , at this very hour , patrol far - off deserts and distant mountains .',\n",
       " 'I stand here today humbled by the task before us , grateful for the trust you have bestowed , mindful of the sacrifices borne by our ancestors .',\n",
       " 'For us , they toiled in sweatshops and settled the West ; endured the lash of the whip and plowed the hard earth .',\n",
       " 'To the people of poor nations , we pledge to work alongside you to make your farms flourish and let clean waters flow ; to nourish starved bodies and feed hungry minds .',\n",
       " 'To the Muslim world , we seek a new way forward , based on mutual interest and mutual respect .',\n",
       " 'Today I say to you that the challenges we face are real .',\n",
       " 'For we know that our patchwork heritage is a strength , not a weakness .',\n",
       " 'That we are in the midst of crisis is now well understood .',\n",
       " 'What the cynics fail to understand is that the ground has shifted beneath them  that the stale political arguments that have consumed us for so long no longer apply .',\n",
       " 'Recall that earlier generations faced down fascism and communism not just with missiles and tanks , but with the sturdy alliances and enduring convictions .',\n",
       " 'Nor is the question before us whether the market is a force for good or ill . Its power to generate wealth and expand freedom is unmatched , but this crisis has reminded us that without a watchful eye , the market can spin out of control  the nation cannot prosper long when it favors only the prosperous .',\n",
       " 'We remain a young nation , but in the words of Scripture , the time has come to set aside childish things .',\n",
       " 'America !',\n",
       " 'So it has been .',\n",
       " 'My fellow citizens :']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimenstion Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent variance captured by all components: 100.0\n",
      "Component 0:\n",
      "That we are in the midst of crisis is now well understood .                                                                                                                                                                                                                                                           0.880238\n",
      "These are the indicators of crisis , subject to data and statistics .                                                                                                                                                                                                                                                 0.880238\n",
      "Nor is the question before us whether the market is a force for good or ill . Its power to generate wealth and expand freedom is unmatched , but this crisis has reminded us that without a watchful eye , the market can spin out of control  the nation cannot prosper long when it favors only the prosperous .    0.825004\n",
      "Now , there are some who question the scale of our ambitions  who suggest that our system cannot tolerate too many big plans .                                                                                                                                                                                        0.304571\n",
      "For us , they fought and died , in places like Concord and Gettysburg ; Normandy and Khe Sahn .                                                                                                                                                                                                                       0.258607\n",
      "What the cynics fail to understand is that the ground has shifted beneath them  that the stale political arguments that have consumed us for so long no longer apply .                                                                                                                                                0.232996\n",
      "On this day , we come to proclaim an end to the petty grievances and false promises , the recriminations and worn - out dogmas that for far too long have strangled our politics .                                                                                                                                    0.220449\n",
      "We remain a young nation , but in the words of Scripture , the time has come to set aside childish things .                                                                                                                                                                                                           0.185284\n",
      "On this day , we gather because we have chosen hope over fear , unity of purpose over conflict and discord .                                                                                                                                                                                                          0.043887\n",
      "As we consider the road that unfolds before us , we remember with humble gratitude those brave Americans who , at this very hour , patrol far - off deserts and distant mountains .                                                                                                                                   0.043887\n",
      "Name: 0, dtype: float64\n",
      "Component 1:\n",
      "On this day , we come to proclaim an end to the petty grievances and false promises , the recriminations and worn - out dogmas that for far too long have strangled our politics .                                                                                                                                    7.614095e-01\n",
      "We remain a young nation , but in the words of Scripture , the time has come to set aside childish things .                                                                                                                                                                                                           5.046799e-01\n",
      "What the cynics fail to understand is that the ground has shifted beneath them  that the stale political arguments that have consumed us for so long no longer apply .                                                                                                                                                4.474078e-01\n",
      "On this day , we gather because we have chosen hope over fear , unity of purpose over conflict and discord .                                                                                                                                                                                                          3.271385e-01\n",
      "As we consider the road that unfolds before us , we remember with humble gratitude those brave Americans who , at this very hour , patrol far - off deserts and distant mountains .                                                                                                                                   3.271385e-01\n",
      "Nor is the question before us whether the market is a force for good or ill . Its power to generate wealth and expand freedom is unmatched , but this crisis has reminded us that without a watchful eye , the market can spin out of control  the nation cannot prosper long when it favors only the prosperous .    2.431187e-01\n",
      "Time and again these men and women struggled and sacrificed and worked till their hands were raw so that we might live a better life .                                                                                                                                                                                2.248843e-01\n",
      "Now , there are some who question the scale of our ambitions  who suggest that our system cannot tolerate too many big plans .                                                                                                                                                                                        1.937009e-01\n",
      "I stand here today humbled by the task before us , grateful for the trust you have bestowed , mindful of the sacrifices borne by our ancestors .                                                                                                                                                                      1.120233e-15\n",
      "Today I say to you that the challenges we face are real .                                                                                                                                                                                                                                                             9.798855e-16\n",
      "Name: 1, dtype: float64\n",
      "Component 2:\n",
      "I stand here today humbled by the task before us , grateful for the trust you have bestowed , mindful of the sacrifices borne by our ancestors .                                       8.536321e-01\n",
      "Today I say to you that the challenges we face are real .                                                                                                                              8.536321e-01\n",
      "To the Muslim world , we seek a new way forward , based on mutual interest and mutual respect .                                                                                        6.370819e-16\n",
      "To the people of poor nations , we pledge to work alongside you to make your farms flourish and let clean waters flow ; to nourish starved bodies and feed hungry minds .              4.372982e-16\n",
      "That we are in the midst of crisis is now well understood .                                                                                                                            2.387456e-16\n",
      "These are the indicators of crisis , subject to data and statistics .                                                                                                                  2.386581e-16\n",
      "As we consider the road that unfolds before us , we remember with humble gratitude those brave Americans who , at this very hour , patrol far - off deserts and distant mountains .    1.315895e-16\n",
      "For us , they toiled in sweatshops and settled the West ; endured the lash of the whip and plowed the hard earth .                                                                     0.000000e+00\n",
      "So it has been .                                                                                                                                                                       0.000000e+00\n",
      "My fellow citizens :                                                                                                                                                                   0.000000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: 2, dtype: float64\n",
      "Component 3:\n",
      "Now , there are some who question the scale of our ambitions  who suggest that our system cannot tolerate too many big plans .                                                                                                                                                                                        7.767636e-01\n",
      "Nor is the question before us whether the market is a force for good or ill . Its power to generate wealth and expand freedom is unmatched , but this crisis has reminded us that without a watchful eye , the market can spin out of control  the nation cannot prosper long when it favors only the prosperous .    3.987467e-01\n",
      "For us , they fought and died , in places like Concord and Gettysburg ; Normandy and Khe Sahn .                                                                                                                                                                                                                       1.861678e-01\n",
      "What the cynics fail to understand is that the ground has shifted beneath them  that the stale political arguments that have consumed us for so long no longer apply .                                                                                                                                                1.427117e-01\n",
      "To the Muslim world , we seek a new way forward , based on mutual interest and mutual respect .                                                                                                                                                                                                                       4.203374e-16\n",
      "I stand here today humbled by the task before us , grateful for the trust you have bestowed , mindful of the sacrifices borne by our ancestors .                                                                                                                                                                      3.325890e-16\n",
      "To the people of poor nations , we pledge to work alongside you to make your farms flourish and let clean waters flow ; to nourish starved bodies and feed hungry minds .                                                                                                                                             4.962461e-17\n",
      "So it has been .                                                                                                                                                                                                                                                                                                     -0.000000e+00\n",
      "For us , they toiled in sweatshops and settled the West ; endured the lash of the whip and plowed the hard earth .                                                                                                                                                                                                   -0.000000e+00\n",
      "My fellow citizens :                                                                                                                                                                                                                                                                                                 -0.000000e+00\n",
      "Name: 3, dtype: float64\n",
      "Component 4:\n",
      "Time and again these men and women struggled and sacrificed and worked till their hands were raw so that we might live a better life .                          7.649352e-01\n",
      "We remain a young nation , but in the words of Scripture , the time has come to set aside childish things .                                                     6.405585e-01\n",
      "That we are in the midst of crisis is now well understood .                                                                                                     2.577189e-02\n",
      "These are the indicators of crisis , subject to data and statistics .                                                                                           2.577189e-02\n",
      "I stand here today humbled by the task before us , grateful for the trust you have bestowed , mindful of the sacrifices borne by our ancestors .                5.399651e-16\n",
      "Today I say to you that the challenges we face are real .                                                                                                       8.533447e-17\n",
      "My fellow citizens :                                                                                                                                            0.000000e+00\n",
      "America !                                                                                                                                                       0.000000e+00\n",
      "Recall that earlier generations faced down fascism and communism not just with missiles and tanks , but with the sturdy alliances and enduring convictions .    0.000000e+00\n",
      "For we know that our patchwork heritage is a strength , not a weakness .                                                                                        0.000000e+00\n",
      "Name: 4, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "#Our SVD data reducer.  We are going to reduce the feature space from 1379 to 130.\n",
    "svd= TruncatedSVD(14)\n",
    "lsa = make_pipeline(svd, Normalizer(copy=False))\n",
    "# Run SVD on the training data, then project the training data.\n",
    "X_train_lsa1 = lsa.fit_transform(X_train_tfidf1)\n",
    "\n",
    "variance_explained=svd.explained_variance_ratio_\n",
    "total_variance = variance_explained.sum()\n",
    "print(\"Percent variance captured by all components:\",total_variance*100)\n",
    "\n",
    "#Looking at what sorts of paragraphs our solution considers similar, for the first five identified topics\n",
    "paras_by_component1=pd.DataFrame(X_train_lsa1,index=X_train1)\n",
    "for i in range(5):\n",
    "    print('Component {}:'.format(i))\n",
    "    print(paras_by_component1.loc[:,i].sort_values(ascending=False)[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent variance captured by all components: 97.42540729824451\n",
      "Component 0:\n",
      "We have learned that we cannot live alone , at peace ; that our own well - being is dependent on the well - being of other nations far away .                                                           0.865649\n",
      "We have learned the simple truth , as Emerson said , that \" The only way to have a friend is to be one .\"                                                                                               0.737397\n",
      "We have learned to be citizens of the world , members of the human community .                                                                                                                          0.696763\n",
      "We can and we will achieve such a peace .                                                                                                                                                               0.527640\n",
      "So we pray to Him now for the vision to see our way clearly  to see the way that leads to a better life for ourselves and for all our fellow men  to the achievement of His will to peace on earth .    0.474607\n",
      "Chief Justice , Mr . Vice President , my friends , you will understand and , I believe , agree with my wish that the form of this inauguration be simple and its words brief .                          0.276818\n",
      "I remember that my old schoolmaster , Dr . Peabody , said , in days that seemed to us then to be secure and untroubled : \" Things in life will not always run smoothly .                                0.230186\n",
      "As I stand here today , having taken the solemn oath of office in the presence of my fellow countrymen  in the presence of our God  I know that it is America ' s purpose that we shall not fail .      0.084701\n",
      "The Almighty God has blessed our land in many ways .                                                                                                                                                    0.034807\n",
      "Name: 0, dtype: float64\n",
      "Component 1:\n",
      "As I stand here today , having taken the solemn oath of office in the presence of my fellow countrymen  in the presence of our God  I know that it is America ' s purpose that we shall not fail .      0.856632\n",
      "The Almighty God has blessed our land in many ways .                                                                                                                                                    0.803008\n",
      "So we pray to Him now for the vision to see our way clearly  to see the way that leads to a better life for ourselves and for all our fellow men  to the achievement of His will to peace on earth .    0.300954\n",
      "I remember that my old schoolmaster , Dr . Peabody , said , in days that seemed to us then to be secure and untroubled : \" Things in life will not always run smoothly .                                0.155410\n",
      "We have learned the simple truth , as Emerson said , that \" The only way to have a friend is to be one .\"                                                                                               0.102786\n",
      "Chief Justice , Mr . Vice President , my friends , you will understand and , I believe , agree with my wish that the form of this inauguration be simple and its words brief .                          0.088018\n",
      "We can and we will achieve such a peace .                                                                                                                                                              -0.103654\n",
      "We have learned to be citizens of the world , members of the human community .                                                                                                                         -0.191758\n",
      "We have learned that we cannot live alone , at peace ; that our own well - being is dependent on the well - being of other nations far away .                                                          -0.210207\n",
      "Name: 1, dtype: float64\n",
      "Component 2:\n",
      "Chief Justice , Mr . Vice President , my friends , you will understand and , I believe , agree with my wish that the form of this inauguration be simple and its words brief .                          0.639122\n",
      "We have learned the simple truth , as Emerson said , that \" The only way to have a friend is to be one .\"                                                                                               0.639007\n",
      "I remember that my old schoolmaster , Dr . Peabody , said , in days that seemed to us then to be secure and untroubled : \" Things in life will not always run smoothly .                                0.408595\n",
      "So we pray to Him now for the vision to see our way clearly  to see the way that leads to a better life for ourselves and for all our fellow men  to the achievement of His will to peace on earth .    0.110880\n",
      "We have learned to be citizens of the world , members of the human community .                                                                                                                         -0.113124\n",
      "As I stand here today , having taken the solemn oath of office in the presence of my fellow countrymen  in the presence of our God  I know that it is America ' s purpose that we shall not fail .     -0.216657\n",
      "The Almighty God has blessed our land in many ways .                                                                                                                                                   -0.237213\n",
      "We have learned that we cannot live alone , at peace ; that our own well - being is dependent on the well - being of other nations far away .                                                          -0.430005\n",
      "We can and we will achieve such a peace .                                                                                                                                                              -0.514839\n",
      "Name: 2, dtype: float64\n",
      "Component 3:\n",
      "So we pray to Him now for the vision to see our way clearly  to see the way that leads to a better life for ourselves and for all our fellow men  to the achievement of His will to peace on earth .    0.619224\n",
      "I remember that my old schoolmaster , Dr . Peabody , said , in days that seemed to us then to be secure and untroubled : \" Things in life will not always run smoothly .                                0.446834\n",
      "We can and we will achieve such a peace .                                                                                                                                                               0.440224\n",
      "We have learned that we cannot live alone , at peace ; that our own well - being is dependent on the well - being of other nations far away .                                                          -0.103263\n",
      "As I stand here today , having taken the solemn oath of office in the presence of my fellow countrymen  in the presence of our God  I know that it is America ' s purpose that we shall not fail .     -0.103939\n",
      "We have learned the simple truth , as Emerson said , that \" The only way to have a friend is to be one .\"                                                                                              -0.106193\n",
      "Chief Justice , Mr . Vice President , my friends , you will understand and , I believe , agree with my wish that the form of this inauguration be simple and its words brief .                         -0.246039\n",
      "The Almighty God has blessed our land in many ways .                                                                                                                                                   -0.263616\n",
      "We have learned to be citizens of the world , members of the human community .                                                                                                                         -0.546967\n",
      "Name: 3, dtype: float64\n",
      "Component 4:\n",
      "Chief Justice , Mr . Vice President , my friends , you will understand and , I believe , agree with my wish that the form of this inauguration be simple and its words brief .                          6.343398e-01\n",
      "We can and we will achieve such a peace .                                                                                                                                                               4.186210e-01\n",
      "As I stand here today , having taken the solemn oath of office in the presence of my fellow countrymen  in the presence of our God  I know that it is America ' s purpose that we shall not fail .      2.325790e-16\n",
      "We have learned the simple truth , as Emerson said , that \" The only way to have a friend is to be one .\"                                                                                               1.036217e-16\n",
      "The Almighty God has blessed our land in many ways .                                                                                                                                                   -0.000000e+00\n",
      "We have learned that we cannot live alone , at peace ; that our own well - being is dependent on the well - being of other nations far away .                                                          -1.569082e-16\n",
      "So we pray to Him now for the vision to see our way clearly  to see the way that leads to a better life for ourselves and for all our fellow men  to the achievement of His will to peace on earth .   -3.372138e-16\n",
      "We have learned to be citizens of the world , members of the human community .                                                                                                                         -3.859108e-01\n",
      "I remember that my old schoolmaster , Dr . Peabody , said , in days that seemed to us then to be secure and untroubled : \" Things in life will not always run smoothly .                               -5.407913e-01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: 4, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Our SVD data reducer.  We are going to reduce the feature space from 1379 to 130.\n",
    "svd= TruncatedSVD(7)\n",
    "lsa = make_pipeline(svd, Normalizer(copy=False))\n",
    "# Run SVD on the training data, then project the training data.\n",
    "X_train_lsa = lsa.fit_transform(X_train_tfidf)\n",
    "\n",
    "variance_explained=svd.explained_variance_ratio_\n",
    "total_variance = variance_explained.sum()\n",
    "print(\"Percent variance captured by all components:\",total_variance*100)\n",
    "\n",
    "#Looking at what sorts of paragraphs our solution considers similar, for the first five identified topics\n",
    "paras_by_component=pd.DataFrame(X_train_lsa,index=X_train)\n",
    "for i in range(5):\n",
    "    print('Component {}:'.format(i))\n",
    "    print(paras_by_component.loc[:,i].sort_values(ascending=False)[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key:\n",
      "0 The Almighty God has blessed our land in many ways .\n",
      "1 We have learned that we cannot live alone , at peace ; that our own well - being is dependent on the well - being of other nations far away .\n",
      "2 I remember that my old schoolmaster , Dr . Peabody , said , in days that seemed to us then to be secure and untroubled : \" Things in life will not always run smoothly .\n",
      "3 So we pray to Him now for the vision to see our way clearly  to see the way that leads to a better life for ourselves and for all our fellow men  to the achievement of His will to peace on earth .\n",
      "4 We have learned to be citizens of the world , members of the human community .\n",
      "5 As I stand here today , having taken the solemn oath of office in the presence of my fellow countrymen  in the presence of our God  I know that it is America ' s purpose that we shall not fail .\n",
      "6 Chief Justice , Mr . Vice President , my friends , you will understand and , I believe , agree with my wish that the form of this inauguration be simple and its words brief .\n",
      "7 We can and we will achieve such a peace .\n",
      "8 We have learned the simple truth , as Emerson said , that \" The only way to have a friend is to be one .\"\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "# Compute document similarity using LSA components\n",
    "similarity = np.asarray(np.asmatrix(X_train_lsa) * np.asmatrix(X_train_lsa).T)\n",
    "#Only taking the first 10 sentences\n",
    "sim_matrix=pd.DataFrame(similarity,index=X_train).iloc[0:9,0:9]\n",
    "#Making a plot\n",
    "ax = sns.heatmap(sim_matrix,yticklabels=range(9))\n",
    "plt.show()\n",
    "\n",
    "#Generating a key for the plot.\n",
    "#put len instead of hardcoding!!!!!!!!!!!\n",
    "print('Key:')\n",
    "for i in range(9):\n",
    "    print(i,sim_matrix.index[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key:\n",
      "0 On this day , we come to proclaim an end to the petty grievances and false promises , the recriminations and worn - out dogmas that for far too long have strangled our politics .\n",
      "1 For us , they fought and died , in places like Concord and Gettysburg ; Normandy and Khe Sahn .\n",
      "2 These are the indicators of crisis , subject to data and statistics .\n",
      "3 Now , there are some who question the scale of our ambitions  who suggest that our system cannot tolerate too many big plans .\n",
      "4 Time and again these men and women struggled and sacrificed and worked till their hands were raw so that we might live a better life .\n",
      "5 On this day , we gather because we have chosen hope over fear , unity of purpose over conflict and discord .\n",
      "6 As we consider the road that unfolds before us , we remember with humble gratitude those brave Americans who , at this very hour , patrol far - off deserts and distant mountains .\n",
      "7 I stand here today humbled by the task before us , grateful for the trust you have bestowed , mindful of the sacrifices borne by our ancestors .\n",
      "8 For us , they toiled in sweatshops and settled the West ; endured the lash of the whip and plowed the hard earth .\n",
      "9 To the people of poor nations , we pledge to work alongside you to make your farms flourish and let clean waters flow ; to nourish starved bodies and feed hungry minds .\n",
      "10 To the Muslim world , we seek a new way forward , based on mutual interest and mutual respect .\n",
      "11 Today I say to you that the challenges we face are real .\n",
      "12 For we know that our patchwork heritage is a strength , not a weakness .\n",
      "13 That we are in the midst of crisis is now well understood .\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "# Compute document similarity using LSA components\n",
    "similarity = np.asarray(np.asmatrix(X_train_lsa1) * np.asmatrix(X_train_lsa1).T)\n",
    "#Only taking the first 10 sentences\n",
    "sim_matrix=pd.DataFrame(similarity,index=X_train1).iloc[0:14,0:14]\n",
    "#Making a plot\n",
    "ax = sns.heatmap(sim_matrix,yticklabels=range(14))\n",
    "plt.show()\n",
    "\n",
    "#Generating a key for the plot.\n",
    "#put len instead of hardcoding!!!!!!!!!!!\n",
    "print('Key:')\n",
    "for i in range(14):\n",
    "    print(i,sim_matrix.index[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aim N 1: We found which are the most frequent words that the presidents used in their inaugurals.For example, \n",
    "Truman: 'world', Reagan - 'people', both Bus Sr and Clinton used 'new' most frequently and Obama used 'nation' the most. We created several different models to determine if a word belongs to a presidents who is a democrat or to e president that is a republican.\n",
    "\n",
    "Aim N 2: We used tfidf to divide the Obama and Roosevelt's inaugurals by paragraphs and determine the importance of the words in each sentence. We are not looking at the frequency only, but the weight of the words as well. We also reduced the number of the features and compared their similarity. The matrix shows low similarity between the components which means that the classification of each component is more distinct with the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
